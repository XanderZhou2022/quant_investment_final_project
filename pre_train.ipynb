{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7b54952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状: (120, 11)\n",
      "因子列表: ['MOM20', 'MOM120', 'RSI', 'PB', 'PE', 'DIV', 'ROE', 'PROFIT_GR', 'VOL', 'BETA']\n",
      "\n",
      "滑动窗口构造完成:\n",
      "X shape: (108, 12, 10)\n",
      "y shape: (108, 10)\n",
      "\n",
      "数据集划分:\n",
      "训练集: X_train (86, 12, 10), y_train (86, 10)\n",
      "测试集: X_test (22, 12, 10), y_test (22, 10)\n",
      "\n",
      "完成！已保存到 data/\n",
      "- X_train.npy, y_train.npy\n",
      "- X_test.npy, y_test.npy\n",
      "- factor_names.txt\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ============================================\n",
    "# 配置区\n",
    "# ============================================\n",
    "\n",
    "data_folder = 'data'\n",
    "window_size = 12  # 输入窗口：过去12期\n",
    "train_ratio = 0.8  # 训练集比例\n",
    "\n",
    "# ============================================\n",
    "# 主流程\n",
    "# ============================================\n",
    "\n",
    "# 1. 读取数据\n",
    "df = pd.read_csv(f'{data_folder}/factor_longshort.csv')\n",
    "print(f\"原始数据形状: {df.shape}\")\n",
    "\n",
    "# 去掉日期列，只保留因子收益\n",
    "factor_names = df.columns[1:].tolist()\n",
    "data = df[factor_names].values\n",
    "print(f\"因子列表: {factor_names}\")\n",
    "\n",
    "# 2. 处理缺失值和异常值\n",
    "data = np.nan_to_num(data, nan=0.0)  # 缺失值填0\n",
    "\n",
    "# 3. 构造滑动窗口样本\n",
    "X, y = [], []\n",
    "for i in range(window_size, len(data)):\n",
    "    X.append(data[i-window_size:i])  # 过去12期作为输入\n",
    "    y.append(data[i])                 # 下一期作为输出\n",
    "\n",
    "X = np.array(X)  # shape: (samples, window_size, num_factors)\n",
    "y = np.array(y)  # shape: (samples, num_factors)\n",
    "\n",
    "print(f\"\\n滑动窗口构造完成:\")\n",
    "print(f\"X shape: {X.shape}\")\n",
    "print(f\"y shape: {y.shape}\")\n",
    "\n",
    "# 4. 划分训练集和测试集\n",
    "split_idx = int(len(X) * train_ratio)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "print(f\"\\n数据集划分:\")\n",
    "print(f\"训练集: X_train {X_train.shape}, y_train {y_train.shape}\")\n",
    "print(f\"测试集: X_test {X_test.shape}, y_test {y_test.shape}\")\n",
    "\n",
    "# 5. 保存数据\n",
    "np.save(f'{data_folder}/X_train.npy', X_train)\n",
    "np.save(f'{data_folder}/y_train.npy', y_train)\n",
    "np.save(f'{data_folder}/X_test.npy', X_test)\n",
    "np.save(f'{data_folder}/y_test.npy', y_test)\n",
    "\n",
    "# 保存因子名称\n",
    "with open(f'{data_folder}/factor_names.txt', 'w') as f:\n",
    "    f.write(','.join(factor_names))\n",
    "\n",
    "print(f\"\\n完成！已保存到 {data_folder}/\")\n",
    "print(\"- X_train.npy, y_train.npy\")\n",
    "print(\"- X_test.npy, y_test.npy\")\n",
    "print(\"- factor_names.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d0848ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "因子数量: 10\n",
      "训练集: (86, 12, 10), 测试集: (22, 12, 10)\n",
      "FactorLSTM(\n",
      "  (lstm): LSTM(10, 64, num_layers=2, batch_first=True, dropout=0.2)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n",
      "\n",
      "开始训练...\n",
      "Epoch 10/100, Loss: 32.6543\n",
      "Epoch 20/100, Loss: 29.8312\n",
      "Epoch 30/100, Loss: 27.0859\n",
      "Epoch 40/100, Loss: 22.0712\n",
      "Epoch 50/100, Loss: 18.6537\n",
      "Epoch 60/100, Loss: 15.0597\n",
      "Epoch 70/100, Loss: 13.3991\n",
      "Epoch 80/100, Loss: 12.9479\n",
      "Epoch 90/100, Loss: 12.0378\n",
      "Epoch 100/100, Loss: 9.9292\n",
      "\n",
      "预测完成，预测结果 shape: (22, 10)\n",
      "\n",
      "已保存到 data/factor_prediction.csv\n",
      "\n",
      "预测结果预览:\n",
      "           日期  MOM20_pred  MOM120_pred  RSI_pred    PB_pred   PE_pred  \\\n",
      "0  2023-03-01   -3.505605    -3.394677 -2.102957   3.386605  3.749079   \n",
      "1  2023-04-01   -2.381520    -2.273877 -1.335405   0.958414  1.704972   \n",
      "2  2023-05-01    1.242640     1.370278  0.862291  -8.359152 -7.256452   \n",
      "3  2023-06-01   -3.148259    -3.126997 -2.814463 -10.009925 -8.612885   \n",
      "4  2023-07-01   -1.507943    -1.606989 -1.536146  -7.645605 -5.218080   \n",
      "\n",
      "   DIV_pred  ROE_pred  PROFIT_GR_pred  VOL_pred  BETA_pred  \n",
      "0  5.409813  0.774587       -1.431851  5.203986   3.944773  \n",
      "1  3.919818  1.229157       -1.292795  2.244080   2.089893  \n",
      "2 -6.215455  2.043941        1.777268 -7.940341  -3.823519  \n",
      "3 -7.829228  2.014737        1.941600 -8.718904  -4.280800  \n",
      "4 -3.863730  3.255244        1.616458 -6.043872  -3.252427  \n",
      "\n",
      "模型已保存到 data/factor_lstm_model.pth\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# ============================================\n",
    "# 配置区\n",
    "# ============================================\n",
    "\n",
    "data_folder = 'data'\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "learning_rate = 0.001\n",
    "epochs = 100\n",
    "batch_size = 16\n",
    "\n",
    "# ============================================\n",
    "# 1. 加载数据\n",
    "# ============================================\n",
    "\n",
    "X_train = np.load(f'{data_folder}/X_train.npy')\n",
    "y_train = np.load(f'{data_folder}/y_train.npy')\n",
    "X_test = np.load(f'{data_folder}/X_test.npy')\n",
    "y_test = np.load(f'{data_folder}/y_test.npy')\n",
    "\n",
    "with open(f'{data_folder}/factor_names.txt', 'r') as f:\n",
    "    factor_names = f.read().strip().split(',')\n",
    "\n",
    "num_factors = len(factor_names)\n",
    "print(f\"因子数量: {num_factors}\")\n",
    "print(f\"训练集: {X_train.shape}, 测试集: {X_test.shape}\")\n",
    "\n",
    "# 转为Tensor\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "y_train_t = torch.FloatTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "y_test_t = torch.FloatTensor(y_test)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    TensorDataset(X_train_t, y_train_t), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# ============================================\n",
    "# 2. 定义LSTM模型\n",
    "# ============================================\n",
    "\n",
    "class FactorLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(FactorLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=0.2\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, seq_len, input_size)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        # 取最后一个时间步\n",
    "        out = self.fc(lstm_out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "model = FactorLSTM(\n",
    "    input_size=num_factors,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    output_size=num_factors\n",
    ")\n",
    "\n",
    "print(model)\n",
    "\n",
    "# ============================================\n",
    "# 3. 训练模型\n",
    "# ============================================\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(\"\\n开始训练...\")\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# ============================================\n",
    "# 4. 测试集预测\n",
    "# ============================================\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_t).numpy()\n",
    "\n",
    "print(f\"\\n预测完成，预测结果 shape: {y_pred.shape}\")\n",
    "\n",
    "# ============================================\n",
    "# 5. 保存预测结果\n",
    "# ============================================\n",
    "\n",
    "# 读取原始数据获取日期\n",
    "df = pd.read_csv(f'{data_folder}/factor_longshort.csv')\n",
    "window_size = 12\n",
    "train_ratio = 0.8\n",
    "total_samples = len(df) - window_size\n",
    "split_idx = int(total_samples * train_ratio)\n",
    "\n",
    "# 测试集对应的日期\n",
    "test_dates = df['日期'].iloc[window_size + split_idx:].values\n",
    "\n",
    "# 构建预测结果DataFrame\n",
    "pred_columns = [f'{name}_pred' for name in factor_names]\n",
    "pred_df = pd.DataFrame(y_pred, columns=pred_columns)\n",
    "pred_df.insert(0, '日期', test_dates)\n",
    "\n",
    "# 保存\n",
    "pred_df.to_csv(f'{data_folder}/factor_prediction.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"\\n已保存到 {data_folder}/factor_prediction.csv\")\n",
    "print(\"\\n预测结果预览:\")\n",
    "print(pred_df.head())\n",
    "\n",
    "# 保存模型\n",
    "torch.save(model.state_dict(), f'{data_folder}/factor_lstm_model.pth')\n",
    "print(f\"\\n模型已保存到 {data_folder}/factor_lstm_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06bd053",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
